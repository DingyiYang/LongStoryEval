name: llama
channels:
  - defaults
dependencies:
  - _libgcc_mutex=0.1=main
  - _openmp_mutex=5.1=1_gnu
  - ca-certificates=2024.7.2=h06a4308_0
  - ld_impl_linux-64=2.38=h1181459_1
  - libffi=3.3=he6710b0_2
  - libgcc-ng=11.2.0=h1234567_1
  - libgomp=11.2.0=h1234567_1
  - libstdcxx-ng=11.2.0=h1234567_1
  - ncurses=6.4=h6a678d5_0
  - openssl=1.1.1w=h7f8727e_0
  - pip=24.2=py38h06a4308_0
  - python=3.8.8=hdb3f193_5
  - readline=8.2=h5eee18b_0
  - setuptools=72.1.0=py38h06a4308_0
  - sqlite=3.45.3=h5eee18b_0
  - tk=8.6.14=h39e8969_0
  - wheel=0.43.0=py38h06a4308_0
  - xz=5.4.6=h5eee18b_1
  - zlib=1.2.13=h5eee18b_1
  - pip:
    - accelerate==0.33.0
    - addict==2.4.0
    - aiohappyeyeballs==2.4.0
    - aiohttp==3.10.5
    - aiosignal==1.3.1
    - aliyun-python-sdk-core==2.15.2
    - aliyun-python-sdk-kms==2.16.5
    - anyio==4.5.2
    - async-timeout==4.0.3
    - attrs==24.2.0
    - bitsandbytes==0.43.0
    - certifi==2024.8.30
    - cffi==1.17.1
    - charset-normalizer==3.3.2
    - click==8.1.7
    - cmake==3.30.3
    - crcmod==1.7
    - cryptography==43.0.1
    - datasets==2.18.0
    - deepspeed==0.9.4
    - dill==0.3.8
    - einops==0.8.0
    - exceptiongroup==1.2.2
    - fastapi==0.115.2
    - filelock==3.16.0
    - flash-attn==2.5.6
    - frozenlist==1.4.1
    - fsspec==2024.2.0
    - gast==0.6.0
    - h11==0.14.0
    - hjson==3.1.0
    - huggingface-hub==0.24.7
    - idna==3.8
    - importlib-metadata==8.5.0
    - jinja2==3.1.3
    - jmespath==0.10.0
    - lit==18.1.8
    - markupsafe==2.1.5
    - modelscope==1.13.3
    - mpmath==1.3.0
    - multidict==6.1.0
    - multiprocess==0.70.16
    - networkx==3.1
    - ninja==1.11.1.1
    - numpy==1.24.4
    - nvidia-cublas-cu11==11.10.3.66
    - nvidia-cuda-cupti-cu11==11.7.101
    - nvidia-cuda-nvrtc-cu11==11.7.99
    - nvidia-cuda-runtime-cu11==11.7.99
    - nvidia-cudnn-cu11==8.5.0.96
    - nvidia-cufft-cu11==10.9.0.58
    - nvidia-curand-cu11==10.2.10.91
    - nvidia-cusolver-cu11==11.4.0.1
    - nvidia-cusparse-cu11==11.7.4.91
    - nvidia-nccl-cu11==2.14.3
    - nvidia-nvtx-cu11==11.7.91
    - opencv-python==4.10.0.84
    - oss2==2.19.0
    - packaging==24.1
    - pandas==1.4.4
    - peft==0.5.0
    - pillow==10.4.0
    - platformdirs==4.3.2
    - psutil==6.0.0
    - py-cpuinfo==9.0.0
    - pyarrow==17.0.0
    - pyarrow-hotfix==0.6
    - pycparser==2.22
    - pycryptodome==3.20.0
    - pydantic==1.10.6
    - python-dateutil==2.9.0.post0
    - pytz==2024.2
    - pyyaml==6.0.2
    - regex==2024.9.11
    - requests==2.32.3
    - safetensors==0.4.5
    - scipy==1.10.1
    - simplejson==3.19.3
    - six==1.16.0
    - sniffio==1.3.1
    - sortedcontainers==2.4.0
    - starlette==0.39.2
    - sympy==1.13.2
    - tokenizers==0.19.1
    - tomli==2.0.1
    - torch==2.0.1
    - tqdm==4.66.5
    - transformers==4.43.1
    - triton==2.0.0
    - typing-extensions==4.12.2
    - urllib3==2.2.2
    - uvicorn==0.31.1
    - xxhash==3.5.0
    - yapf==0.40.2
    - yarl==1.11.1
    - zipp==3.20.1
prefix: /root/.conda/envs/llama
